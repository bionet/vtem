#!/usr/bin/env python

import tables
import numpy as np

class vtem_storage(object):
    def __init__(self, filename, num_neurons, filter_type, title = 'VTEM_gabor_iaf'):
        """
            stores spikes generated by VTEM with gabor filters and IAF neurons
            
            filename: name of the h5 file to store the spikes
            num_neurons: number of neurons 
            
            usage closely related to vrf_gabor class and IAF_encode class 
            
            using vtem_storage_read to read this file
            
            video attributes are stored in root.video
            including: Wt, Wx, Wy, Px, Py, dx, dy
            
            gabor filter parameters are stored in root.vrf
            including KAPPA, alpha, l, n, k, ab(real or imaginary)
            
            iaf neuron parameters are stored in root.iaf
            including: kappa, delta, bias
            and refresh_interval
            
            spike info are stored in root.spikes
            including:
            spike_count0: number of spikes of all neurons in 0th refresh_interval  
            spike_count1: number of spikes of all neurons in 1st refresh_interval 
            .... 
            
            spikes0: spikes from all neurons in 0th refresh_interval
            spikes1: spikes from all neurons in 1st refresh_interval
            
            spikes are stored in absolute firing time (not interspike intervals) per refresh interval
            i.e. spikes in the jth refresh interval need to be added by j*root.iaf.refresh_interval.read() to get its true spike time
            
            
            """
        
        
        self.h5file = tables.openFile(filename, mode = 'w', title=title)
        self.h5file.createGroup(self.h5file.root, "video")
        self.h5file.createGroup(self.h5file.root, "vrf")
        self.h5file.createGroup(self.h5file.root, "iaf")
        self.h5file.createGroup(self.h5file.root, "spikes")
        
        
        self.filter_type = filter_type
        
        self.alpha = self.h5file.createEArray("/vrf", "alpha", tables.Float64Atom(), (0,))
        self.x0 = self.h5file.createEArray("/vrf", "x0", tables.Float64Atom(), (0,))
        self.y0 = self.h5file.createEArray("/vrf", "y0", tables.Float64Atom(), (0,))
        
        if filter_type == "gabor":
            self.l = self.h5file.createEArray("/vrf", "l", tables.Float64Atom(), (0,))
            self.ab = self.h5file.createEArray("/vrf", "ab", tables.Int32Atom(), (0,))
        
        self.kappa = self.h5file.createEArray("/iaf", "kappa", tables.Float64Atom(), (0,))
        self.delta = self.h5file.createEArray("/iaf", "delta", tables.Float64Atom(), (0,))
        self.bias = self.h5file.createEArray("/iaf", "bias", tables.Float64Atom(), (0,))
        self.sigma = self.h5file.createEArray("/iaf", "sigma", tables.Float64Atom(), (0,))
        
        #counts the number of refresh intervals
        self.refresh_interval = 0
    
    
    def close(self):
        """ will write total number neurons by inferering the number of gabor parameters
            will write the total number of refresh intervals"""
        try:
            self.h5file.createArray("/vrf", "num_neurons", self.h5file.root.vrf.alpha.__len__())
            self.h5file.createArray("/spikes","total_intervals", self.refresh_interval)
        except:
            pass
        
        self.h5file.close()
    
    def __del__(self):
        if self.h5file.isopen:
            self.close()
    
    
    def write_video_attributes(self,Wt, Wx, Wy, Px, Py, dx, dy):
        """ write video attributes """
        self.h5file.createArray("/video", "Wt", Wt)
        self.h5file.createArray("/video", "Wx", Wy)
        self.h5file.createArray("/video", "Wy", Wx)
        
        self.h5file.createArray("/vrf", "Px", Px)
        self.h5file.createArray("/vrf", "Py", Py)
        self.h5file.createArray("/vrf", "dx", dx)
        self.h5file.createArray("/vrf", "dy", dy)
    
    def write_gabor_parameters(self,filter):
        """
            write gabor filter parameters
            filter: a vrf_gabor class instance, the parameter of which are set
            
            """
        try:
            self.h5file.root.vrf.KAPPA
        except:
            self.h5file.createArray("/vrf", "KAPPA", filter.KAPPA)
        
        
        self.alpha.append(filter.h_alpha)
        self.l.append(filter.h_l)
        self.x0.append(filter.h_x0)
        self.y0.append(filter.h_y0)
        self.ab.append(filter.h_ab)
    
    def write_cs_parameters(self, filter):
        
        try:
            self.h5file.root.vrf.sigma_center
        except:
            self.h5file.createArray("/vrf", "sigma_center", filter.sigma_center)
            self.h5file.createArray("/vrf", "sigma_surround", filter.sigma_surround)
        
        self.alpha.append(filter.h_alpha)
        self.x0.append(filter.h_x0)
        self.y0.append(filter.h_y0)
    
    
    def write_neuron_parameters(self,iaf):
        """
            write iaf neuron parameters
            iaf: a IAF_encode class instance, the parameter of which are set
            """
        self.kappa.append(iaf.h_kappa)
        self.delta.append(iaf.h_delta)
        self.bias.append(iaf.h_bias)
        self.sigma.append(iaf.h_sigma)
    
    def write_refresh_interval(self, time):
        """
            write the refresh interval
            time: the time bin of refresh_interval
            """
        
        self.h5file.createArray("/iaf", "refresh_interval", time)
    
    
    def write_spike_in_timebin(self, spike_count, spikes):
        """
            write the spikes and spike_counts in a time bin
            spike_count: most possibly generated by iaf.encode, containing number of spikes generated by iaf
            spikes: most possibly generated by iaf.encode, containing spike times in the refresh interval
            """
        
        self.h5file.createArray("/spikes", "spike_count"+str(self.refresh_interval), spike_count)
        self.h5file.createArray("/spikes", "spikes"+str(self.refresh_interval), spikes)
        self.refresh_interval+=1


class vtem_storage_read(object):
    def __init__(self, filename):
        """ read spike files stored by vtem_storage """
        
        self.h5file = tables.openFile(filename, mode = 'r')
    
    def close(self):
        self.h5file.close()
    
    def __del__(self):
        self.close()
    
    def read_num_neurons(self):
        """ returns the number of neurons used in the VTEM """
        self.num_neurons = int(self.h5file.root.vrf.num_neurons.read())
        return self.num_neurons
    
    def read_video_attributes(self):
        """
            returns video attributes
            order: Wt,Wx,Wy,Px,Py,dx,dy
            
            """
        Wt = float(self.h5file.root.video.Wt.read())
        Wx = float(self.h5file.root.video.Wx.read())
        Wy = float(self.h5file.root.video.Wy.read())
        
        Px = int(self.h5file.root.vrf.Px.read())
        Py = int(self.h5file.root.vrf.Py.read())
        dx = float(self.h5file.root.vrf.dx.read())
        dy = float(self.h5file.root.vrf.dy.read())
        
        return Wt,Wx,Wy,Px,Py,dx,dy
    
    def read_vrf_type(self):
        try:
            shape = self.h5file.root.vrf.ab.shape
            self.filter_type = "gabor"
        except:
            self.filter_type = "cs"
    
    def read_vrf(self):
        """ read gabor filter parameters
            returns alpha, l, n, k, ab, KAPPA
            """
        if self.filter_type == "gabor":
            h_alpha = self.h5file.root.vrf.alpha.read()
            h_x0 = self.h5file.root.vrf.x0.read()
            h_y0 = self.h5file.root.vrf.y0.read()
            
            h_l = self.h5file.root.vrf.l.read()
            h_ab = self.h5file.root.vrf.ab.read()
            KAPPA = float(self.h5file.root.vrf.KAPPA.read())
            return h_alpha,h_l,h_x0,h_y0,h_ab,KAPPA
        else:
            h_alpha = self.h5file.root.vrf.alpha.read()
            h_x0 = self.h5file.root.vrf.x0.read()
            h_y0 = self.h5file.root.vrf.y0.read()
            sigma_center = float(self.h5file.root.vrf.sigma_center.read())
            sigma_surround = float(self.h5file.root.vrf.sigma_surround.read())
            return h_alpha,h_x0,h_y0,sigma_center,sigma_surround
    
    
    
    def read_refresh_interval(self):
        """ returns the refresh interval length """
        return float(self.h5file.root.iaf.refresh_interval.read())
    
    def read_total_intervals(self):
        """ returns the total number of refresh intervals """
        
        return int(self.h5file.root.spikes.total_intervals.read())
    
    def read_iaf(self):
        """ read iaf neuron parameters
            returns kappa, delta, bias
            """
        
        h_kappa = self.h5file.root.iaf.kappa.read()
        h_delta = self.h5file.root.iaf.delta.read()
        h_bias = self.h5file.root.iaf.bias.read()
        h_sigma = self.h5file.root.iaf.sigma.read()
        return h_kappa,h_delta,h_bias,h_sigma
    
    def select_neurons(self, domain):
        """
            select the neurons to decode
            the neurons selected are centered inside domain
            
            domain: 4-list, [x_start, x_end, y_start, y_end]
            selection will be stored in self
            
            """
        
        if self.filter_type == "gabor":
            h_alpha,h_l,h_x0,h_y0,h_ab,self.KAPPA = self.read_vrf()
        else:
            h_alpha,h_x0,h_y0,self.sigma_center,self.sigma_surround = self.read_vrf()
        
        allind = np.arange(self.num_neurons)
        
        Sx = domain[1]-domain[0]
        Sy = domain[3]-domain[2]
        
        shiftx = domain[0] + Sx / 2
        shifty = domain[2] + Sy / 2 
        
        self.choose = allind[(h_x0 > domain[0]-0.01) & (h_x0 < domain[1] +0.01) & (h_y0 > domain[2]-0.01) & (h_y0 < domain[3]+0.01)]
        self.alpha = h_alpha[self.choose]
        
        self.x0 = h_x0[self.choose] - shiftx
        
        self.y0 = h_y0[self.choose] - shifty
        
        if self.filter_type == "gabor":
            self.l = h_l[self.choose]
            self.ab = h_ab[self.choose]
        
        self.decode_neurons = self.choose.size
    
    def read_select_spikes(self, time_frame):
        """
            read spikes for neurons selected by select_neurons within a time interval indicated by time_frame
            for each neuron, the last spike before the time interval and the first spike after the time interval are
            also read
            
            time_frame: 2-list, [start_time, end_time]
            
            returns:
            tk1: a ndarray vector of float64 containing all the t_k's in \int_{t_k}^{t_{k+1}}
            tk2: a ndarray vector of float64 containing all the t_{k+1}'s in \int_{t_k}^{k+1}}
            neuron_ind: a nddarray vector of int32, where neuron_ind[j] is the neuron index correspond to (tk1[j],tk2[j]) 
            kappa: a ndarray vector of float64 containing the integration constants for each selected neuron 
            delta: a ndarray vector of float64 containing the threshold for each selected neuron
            bias:  a ndarray vector of float64 containing the bias for each selected neuron
            
            
            """
        
        
        h_kappa,h_delta,h_bias,h_sigma = self.read_iaf()
        self.kappa = h_kappa[self.choose]
        self.delta = h_delta[self.choose]
        self.bias = h_bias[self.choose]
        
        refresh_interval = self.read_refresh_interval()
        total_intervals = self.read_total_intervals()
        
        start_interval = int(np.floor(time_frame[0] / refresh_interval))
        end_interval = int(np.floor(time_frame[1] / refresh_interval))
        
        intervals = np.arange(max(0,start_interval-1),min(total_intervals, end_interval+2))
        
        spike_tmp = []
        for i in range(self.decode_neurons):
            spike_tmp.append(np.zeros(0))
        
        for i in intervals:
            spike_count = self.h5file.root.spikes._f_getChild('spike_count'+str(i)).read()
            spike_count_cum = np.concatenate((np.zeros(1,np.int32),np.cumsum(spike_count)),1)
            spikes = self.h5file.root.spikes._f_getChild('spikes'+str(i)).read() + i * refresh_interval - time_frame[0]
            
            for j in range(self.decode_neurons):
                spike_tmp[j] = np.concatenate((spike_tmp[j], spikes[spike_count_cum[self.choose[j]]:spike_count_cum[self.choose[j]+1]]),1)
        
        tk = []
        count = np.zeros(self.decode_neurons,np.int32)
        
        for i in range(self.decode_neurons):
            a = np.nonzero((spike_tmp[i] > 0) & (spike_tmp[i] < time_frame[1]-time_frame[0]))[0]
            
            if a.size > 0:
                tk.append( spike_tmp[i][range(max(0,a[0]-1), min(a[-1]+2, spike_tmp[i].size))])
            else:
                tk.append( np.zeros(0))
            count[i] = max(0,tk[i].size-1)
        del spike_tmp
        
        self.tk = tk
        self.count = count
        
        count_cum = np.concatenate((np.zeros(1,np.int32),np.cumsum(count)),1)
        tk1 = np.empty(count_cum[-1],np.float64)
        tk2 = np.empty(count_cum[-1],np.float64)
        neuron_ind = np.empty(count_cum[-1],np.int32)
        
        for i in range(self.decode_neurons):
            tk1[count_cum[i]:count_cum[i+1]] = tk[i][:-1]
            tk2[count_cum[i]:count_cum[i+1]] = tk[i][1:]
            neuron_ind[count_cum[i]:count_cum[i+1]] = i
        
        
        return tk1,tk2,neuron_ind, self.kappa,self.delta,self.bias,h_sigma


















